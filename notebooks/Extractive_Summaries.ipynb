{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download necessary library from nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Published</th>\n",
       "      <th>Language</th>\n",
       "      <th>System Details</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Description</th>\n",
       "      <th>Description Details</th>\n",
       "      <th>Genre</th>\n",
       "      <th>OCLC</th>\n",
       "      <th>Other Identifiers</th>\n",
       "      <th>System ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998 vital statistics of the United States : v...</td>\n",
       "      <td>Perkins Public Documents/Maps</td>\n",
       "      <td>National Center for Health Statistics (U.S.)</td>\n",
       "      <td>This CD ROM contains chiefly tables, a guide t...</td>\n",
       "      <td>[Washington, D.C.?] : Dept. of Health and Huma...</td>\n",
       "      <td>English</td>\n",
       "      <td>System requirements for Windows: IBM-compatibl...</td>\n",
       "      <td>Title from title screen.ISO 9660 format.\"Shipp...</td>\n",
       "      <td>1 CD-ROM ; 4 3/4 in.</td>\n",
       "      <td>Dimensions: 4 3/4 in.Color characteristics: po...</td>\n",
       "      <td>TablesStatistics, Vital</td>\n",
       "      <td>49537646.0</td>\n",
       "      <td>GPO Item Number: 0510</td>\n",
       "      <td>003072700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12th Education and Training in Optics and Phot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Proceedings of SPIE present the original resea...</td>\n",
       "      <td>[S.l.] : [s.n.], 9999.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Title from content provider.</td>\n",
       "      <td>1 online resource</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electronic books</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>008891635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13th International Scientific Conference on Op...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Proceedings of SPIE present the original resea...</td>\n",
       "      <td>[S.l.] : [s.n.], 9999.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Title from content provider.</td>\n",
       "      <td>1 online resource</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electronic books</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>008891641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16th International Workshop on Physics of Semi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Proceedings of SPIE present the original resea...</td>\n",
       "      <td>[S.l.] : [s.n.], 9999.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Title from content provider.</td>\n",
       "      <td>1 online resource</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electronic books</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>008891649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17th-18th century Burney Collection newspapers...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Burney, Charles, 1757-1817</td>\n",
       "      <td>Searchable full-text access to the British Lib...</td>\n",
       "      <td>[Farmington Hills, Mich.] : Gale Cengage Learn...</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 online resource</td>\n",
       "      <td>Color characteristics: polychromeFile type: te...</td>\n",
       "      <td>SourcesIndexesOnline databasesElectronic refer...</td>\n",
       "      <td>182626961.0</td>\n",
       "      <td>LCCN: 2013238254</td>\n",
       "      <td>003975405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  1998 vital statistics of the United States : v...   \n",
       "1  12th Education and Training in Optics and Phot...   \n",
       "2  13th International Scientific Conference on Op...   \n",
       "3  16th International Workshop on Physics of Semi...   \n",
       "4  17th-18th century Burney Collection newspapers...   \n",
       "\n",
       "                        Location  \\\n",
       "0  Perkins Public Documents/Maps   \n",
       "1                            NaN   \n",
       "2                            NaN   \n",
       "3                            NaN   \n",
       "4                            NaN   \n",
       "\n",
       "                                        Authors  \\\n",
       "0  National Center for Health Statistics (U.S.)   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                    Burney, Charles, 1757-1817   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  This CD ROM contains chiefly tables, a guide t...   \n",
       "1  Proceedings of SPIE present the original resea...   \n",
       "2  Proceedings of SPIE present the original resea...   \n",
       "3  Proceedings of SPIE present the original resea...   \n",
       "4  Searchable full-text access to the British Lib...   \n",
       "\n",
       "                                           Published Language  \\\n",
       "0  [Washington, D.C.?] : Dept. of Health and Huma...  English   \n",
       "1                             [S.l.] : [s.n.], 9999.      NaN   \n",
       "2                             [S.l.] : [s.n.], 9999.      NaN   \n",
       "3                             [S.l.] : [s.n.], 9999.      NaN   \n",
       "4  [Farmington Hills, Mich.] : Gale Cengage Learn...  English   \n",
       "\n",
       "                                      System Details  \\\n",
       "0  System requirements for Windows: IBM-compatibl...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                               Notes           Description  \\\n",
       "0  Title from title screen.ISO 9660 format.\"Shipp...  1 CD-ROM ; 4 3/4 in.   \n",
       "1                       Title from content provider.     1 online resource   \n",
       "2                       Title from content provider.     1 online resource   \n",
       "3                       Title from content provider.     1 online resource   \n",
       "4                                                NaN     1 online resource   \n",
       "\n",
       "                                 Description Details  \\\n",
       "0  Dimensions: 4 3/4 in.Color characteristics: po...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  Color characteristics: polychromeFile type: te...   \n",
       "\n",
       "                                               Genre         OCLC  \\\n",
       "0                            TablesStatistics, Vital   49537646.0   \n",
       "1                                   Electronic books          NaN   \n",
       "2                                   Electronic books          NaN   \n",
       "3                                   Electronic books          NaN   \n",
       "4  SourcesIndexesOnline databasesElectronic refer...  182626961.0   \n",
       "\n",
       "       Other Identifiers  System ID  \n",
       "0  GPO Item Number: 0510  003072700  \n",
       "1                    NaN  008891635  \n",
       "2                    NaN  008891641  \n",
       "3                    NaN  008891649  \n",
       "4       LCCN: 2013238254  003975405  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_data = pd.read_csv('../Data/duke_books.csv')\n",
    "book_data.head()\n",
    "\n",
    "#see how many NA's are in the summary column \n",
    "book_data['Summary'].isna().sum()\n",
    "\n",
    "#drop NA values for now\n",
    "book_data = book_data.dropna(subset = ['Summary']).reset_index(drop = True)\n",
    "\n",
    "#look at data head\n",
    "book_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#many summaries are short and so we don't need to summarize them, lets make a flag column for summary being > 100 words \n",
    "def word_count(text): \n",
    "    words = text.split()\n",
    "    return len(words)\n",
    "\n",
    "#create word count column\n",
    "book_data['word_count'] = book_data['Summary'].apply(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2755"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>African American newspapers, 1827-1998. - Duke...</td>\n",
       "      <td>Provides access to U.S. newspapers chronicling...</td>\n",
       "      <td>African American newspapers, 1827-1998. - Duke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>All the world's primates. - Duke University Li...</td>\n",
       "      <td>All the World's Primates is the comprehensive ...</td>\n",
       "      <td>All the world's primates. - Duke University Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>The American bench. - Duke University Librarie...</td>\n",
       "      <td>Court profiles on both federal and state court...</td>\n",
       "      <td>The American bench. - Duke University Librarie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>American Law Institute library. - Duke Univers...</td>\n",
       "      <td>The American Law Institute library on HeinOnli...</td>\n",
       "      <td>American Law Institute library. - Duke Univers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Archives of sexuality &amp; gender. LGBTQ history ...</td>\n",
       "      <td>As part of the Archives of Sexuality &amp; Gender ...</td>\n",
       "      <td>Archives of sexuality &amp; gender. LGBTQ history ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "119  African American newspapers, 1827-1998. - Duke...   \n",
       "130  All the world's primates. - Duke University Li...   \n",
       "137  The American bench. - Duke University Librarie...   \n",
       "140  American Law Institute library. - Duke Univers...   \n",
       "172  Archives of sexuality & gender. LGBTQ history ...   \n",
       "\n",
       "                                               Summary  \\\n",
       "119  Provides access to U.S. newspapers chronicling...   \n",
       "130  All the World's Primates is the comprehensive ...   \n",
       "137  Court profiles on both federal and state court...   \n",
       "140  The American Law Institute library on HeinOnli...   \n",
       "172  As part of the Archives of Sexuality & Gender ...   \n",
       "\n",
       "                                             full_text  \n",
       "119  African American newspapers, 1827-1998. - Duke...  \n",
       "130  All the world's primates. - Duke University Li...  \n",
       "137  The American bench. - Duke University Librarie...  \n",
       "140  American Law Institute library. - Duke Univers...  \n",
       "172  Archives of sexuality & gender. LGBTQ history ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "African American newspapers, 1827-1998. - Duke University Libraries Catalog Provides access to U.S. newspapers chronicling a century and a half of the African American experience. Includes historically significant papers from more than 35 states and features many rare 19th-century titles. Titles in Series 1 come from the Wisconsin Historical Society, Kansas State Historical Society and the Library of Congress, while titles in Series 2 come from the American Antiquarian Society, Center for Research Libraries, the Library of Congress, and New York Public Library. Covers life in the Antebellum South, growth of the Black church, the Jim Crow Era, the Great Migration, Harlem Renaissance, Civil Rights movement, and political and economic empowerment.\n"
     ]
    }
   ],
   "source": [
    "#filter for books with longer summaries\n",
    "book_long = book_data[book_data['word_count'] >= 100] \n",
    "\n",
    "#drop everything but title and summary \n",
    "book_long = book_long.loc[:, ['Title', 'Summary']]\n",
    "\n",
    "#generate full combinations of title and text\n",
    "book_long['full_text'] = book_long.apply(lambda x: ' '.join([x['Title'],x['Summary']]),axis=1)\n",
    "\n",
    "book_long['full_text'] = book_long['full_text'].astype(str)\n",
    "\n",
    "#see how many observations we have\n",
    "display(len(book_long))\n",
    "display(book_long.head())\n",
    "\n",
    "\n",
    "\n",
    "print(book_long.iloc[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractive_summaries(full_text): \n",
    "\n",
    "    #tokenize sentences\n",
    "    sentences = sent_tokenize(full_text)\n",
    "\n",
    "    #strip alpha numeric characters and stopwords \n",
    "    sentences_processed = []\n",
    "    for sentence in sentences:\n",
    "        sentence_reduced = sentence.replace(\"[^a-zA-Z0-9_]\", '')\n",
    "        sentence_reduced = [word.lower() for word in sentence_reduced.split(' ') if word.lower() not in stopwords.words('english')]\n",
    "        sentences_processed.append(' '.join(word for word in sentence_reduced))\n",
    "\n",
    "    #create TFIDF feature vecs\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    feature_vecs = vectorizer.fit_transform(sentences_processed)\n",
    "    feature_vecs = feature_vecs.todense().tolist()\n",
    "\n",
    "    # Create empty adjacency matrix\n",
    "    adjacency_matrix = np.zeros((len(feature_vecs), len(feature_vecs)))\n",
    " \n",
    "    # Populate the adjacency matrix using the similarity of all pairs of sentences\n",
    "    for i in range(len(feature_vecs)):\n",
    "        for j in range(len(feature_vecs)):\n",
    "            if i == j: #ignore if both are the same sentence\n",
    "                continue \n",
    "            adjacency_matrix[i][j] = 1 - cosine_distance(feature_vecs[1], feature_vecs[j])\n",
    "\n",
    "    # Create the graph representing the document\n",
    "    document_graph = nx.from_numpy_array(adjacency_matrix)\n",
    "\n",
    "    # Apply PageRank algorithm to get centrality scores for each node/sentence\n",
    "    scores = nx.pagerank(document_graph)\n",
    "    scores_list = list(scores.values())\n",
    "\n",
    "    # Sort and pick top sentences\n",
    "    ranking_idx = np.argsort(scores_list)[::-1]\n",
    "    ranked_sentences = [sentences[i] for i in ranking_idx]   \n",
    "\n",
    "    summary = []\n",
    "    top_n = 1\n",
    "    for i in range(top_n):\n",
    "        summary.append(ranked_sentences[i])\n",
    "\n",
    "    summary = \" \".join(summary)\n",
    "    \n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "PowerIterationFailedConvergence",
     "evalue": "(PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPowerIterationFailedConvergence\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m book_long[\u001b[39m'\u001b[39m\u001b[39mextractive_summary\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m book_long[\u001b[39m'\u001b[39;49m\u001b[39mfull_text\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(extractive_summaries)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AIPI540/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AIPI540/lib/python3.10/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AIPI540/lib/python3.10/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AIPI540/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[55], line 32\u001b[0m, in \u001b[0;36mextractive_summaries\u001b[0;34m(full_text)\u001b[0m\n\u001b[1;32m     29\u001b[0m document_graph \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39mfrom_numpy_array(adjacency_matrix)\n\u001b[1;32m     31\u001b[0m \u001b[39m# Apply PageRank algorithm to get centrality scores for each node/sentence\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m scores \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mpagerank(document_graph)\n\u001b[1;32m     33\u001b[0m scores_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(scores\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m     35\u001b[0m \u001b[39m# Sort and pick top sentences\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AIPI540/lib/python3.10/site-packages/networkx/classes/backends.py:145\u001b[0m, in \u001b[0;36m_dispatch.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m             \u001b[39mraise\u001b[39;00m NetworkXNotImplemented(\n\u001b[1;32m    143\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not implemented by \u001b[39m\u001b[39m{\u001b[39;00mplugin_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m             )\n\u001b[0;32m--> 145\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AIPI540/lib/python3.10/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py:109\u001b[0m, in \u001b[0;36mpagerank\u001b[0;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m@nx\u001b[39m\u001b[39m.\u001b[39m_dispatch\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpagerank\u001b[39m(\n\u001b[1;32m     11\u001b[0m     G,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     dangling\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     19\u001b[0m ):\n\u001b[1;32m     20\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the PageRank of the nodes in the graph.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[39m    PageRank computes a ranking of the nodes in the graph G based on\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     \u001b[39mreturn\u001b[39;00m _pagerank_scipy(\n\u001b[1;32m    110\u001b[0m         G, alpha, personalization, max_iter, tol, nstart, weight, dangling\n\u001b[1;32m    111\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AIPI540/lib/python3.10/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py:498\u001b[0m, in \u001b[0;36m_pagerank_scipy\u001b[0;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[39mif\u001b[39;00m err \u001b[39m<\u001b[39m N \u001b[39m*\u001b[39m tol:\n\u001b[1;32m    497\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(nodelist, \u001b[39mmap\u001b[39m(\u001b[39mfloat\u001b[39m, x)))\n\u001b[0;32m--> 498\u001b[0m \u001b[39mraise\u001b[39;00m nx\u001b[39m.\u001b[39mPowerIterationFailedConvergence(max_iter)\n",
      "\u001b[0;31mPowerIterationFailedConvergence\u001b[0m: (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')"
     ]
    }
   ],
   "source": [
    "\n",
    "book_long['extractive_summary'] = book_long['full_text'].apply(extractive_summaries)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIPI540",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
